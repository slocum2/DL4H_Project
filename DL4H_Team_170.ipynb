{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfk8Zrul_E8V"
   },
   "source": [
    "**Deep Learning For Healthcare - Final Project**\n",
    "\n",
    "**Team 170 (Noah Slocum)**\n",
    "\n",
    "**GitHub Repo: https://github.com/slocum2/DL4H_Project**\n",
    "\n",
    "**Video Presentation:** See https://github.com/slocum2/DL4H_Project/blob/main/README.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MQ0sNuMePBXx"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "### Paper citation\n",
    "Feng, YH., Zhang, SW. & Shi, JY. DPDDI: a deep predictor for drug-drug interactions. BMC Bioinformatics 21, 419 (2020). https://doi.org/10.1186/s12859-020-03724-x\n",
    "\n",
    "https://github.com/NWPU-903PR/DPDDI\n",
    "\n",
    "### Background\n",
    "\n",
    "Understanding drug-drug interactions (DDIs) is important to developing any new medication or combinatorial prescription. Medications are frequently prescribed together for desired synergistic effects that may be greater than the effect of either medication alone. On the contrary, taking two medications simultaneously can also be dangerous if they interact to produce undesired or even toxic effects. Traditionally, drug-drug interactions have been investigated and identified in a wet lab, which is costly and very time consuming. This is true whether in vitro or in vivo methods are used. Considering the continuously growing number of drugs available for prescription, this task is only becoming more difficult as time goes on. \n",
    "\n",
    "In contrast to wet-lab methods, computational methods have been used to discover DDIs in two ways: one, by finding annotated DDIs in literature, medical records, and other forms of unstructured text, and two, by predicting DDIs using machine learning and detailed descriptions of drug properties. The former is useful but cannot predict DDIs before combinatorial treatment, while the latter requires that machine learning features be carefully crafted from detailed drug characteristic data (including chemical structure, targets, ATC codes, side effects, and clinical observations). \n",
    "\n",
    "While the latter method is useful in many cases, detailed data about drug properties may not always be available. Drugs without complete data may not be included in DDI prediction models and thus the model may not be pragmatic enough for real scenarios where the ignored drugs can still be combinatorially prescribed. The general problem Feng et al attempt to solve is that of enhancing DDI prediction to eliminate the need for hand-crafted features and to avoid ignoring or removing drugs with incomplete data.\n",
    "\n",
    "In this paper, Feng et al describe a 2-fold approach to solving the problem stated above. First, they use a graph convolution network (GCN) to learn the low-dimensional feature representation of each drug. Using a graph data structure along with a convolutional network captures the topological relationship of each drug to neighboring drugs. This approach is unsupervised and doesnâ€™t require manual feature engineering or complete data for each drug. The second step is feeding the low-dimensional feature representation of each drug (created by the GCN) to a deep neural network (DNN) for DDI prediction. This is done by aggregating features representing two drugs into one feature that represents the DDI.\n",
    "\n",
    "### Hypothesis\n",
    "The hypothesis is that the specific approach described above will perform better than state-of-art DDI predictors. This hypothesis is based on the following ideas:\n",
    "\n",
    "1. The deep learning features created by a GCN will outperform other features hand-crafted from chemical, biological or anatomical properties of drugs.\n",
    "2. The GCN-created features can be aggregated to represent DDIs and then used to train a deep neural network for prediction.\n",
    "\n",
    "### Scope of reproducibility \n",
    "The model proposed by Feng et al can be implemented with Tensorflow and Python which are open source and available to anyone. The authors do not provide any computational data such as the type of hardware used in the study, the average runtime for each epoch, or the GPU-hours consumed. Without this information, I assumed that the study can be replicated on commodity hardware in a reasonable amount of time. In this notebook I tried to recreate this study by adapting code provided by the authors at https://github.com/NWPU-903PR/DPDDI/. I attempted to adapt the code to run on more recent versions of Python, Tensorflow, and SciPy.\n",
    "\n",
    "# Methodology\n",
    "\n",
    "### Environment\n",
    "Windows 10 Enterprise\n",
    "\n",
    "### Python version\n",
    "Python 3.9\n",
    "\n",
    "### Dependencies/packages needed\n",
    "See the requirements file at https://github.com/slocum2/DL4H_Project/blob/main/requirements.txt for all required packages.\n",
    "\n",
    "### Computational requirements\n",
    "- **Hardware**:\n",
    "    - **CPU**: 12th Gen Intel(R) Core(TM) i7-12800H   2.40 GHz\n",
    "    - **GPU**: NVIDIA RTX A1000 Laptop GPU (8GB GPU memory)\n",
    "    - **Installed RAM**: 32 GB\n",
    "    - **System type**: 64-bit operating system, x64-based processor\n",
    "    - **OS**: Windows 10 Enterprise 22H2 (build 19045.4291)\n",
    "- **Average runtime for each epoch**: 10 seconds\n",
    "- **Number of training epochs**: 1200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yu61Jp1xrnKk"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import copy\n",
    "import csv\n",
    "import h5py\n",
    "from keras import *\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "import random\n",
    "import scipy.io as sio\n",
    "import scipy.sparse as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "import tensorflow.compat.v1 as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NbPHUTMbkD3"
   },
   "source": [
    "#  Data\n",
    "\n",
    "### Download instructions\n",
    "There are three datasets of different sizes used by the authors to assess the performance of their model:\n",
    "- DB1: Sourced from https://go.drugbank.com/releases/latest\n",
    "- DB2: vailable at https://github.com/zw9977129/drug-drug-interaction/\n",
    "- DB3: Sourced from https://go.drugbank.com/releases/latest\n",
    "\n",
    "Datasets DB1 and DB3 are available for download from the authors at https://github.com/NWPU-903PR/DPDDI/blob/master/DATA.mat. To use this data, I [installed MATLAB](https://www.mathworks.com/help/install/ug/install-products-with-internet-connection.html) and registered for a free trial. I then opened the file in MATLAB and wrote the variables inside to a HDF5 file in order to use them with the code samples from the authors. The adjacency matrix for DB1 is contained in the Adj_V4 variable, while the adjacency matrix for DB3 is contained in the Adj_V5 variable.\n",
    "\n",
    "### Data description\n",
    "The datasets used in this experiment were as follows:\n",
    "- DB1: 1562 drugs and 180,576 annotated drug-drug interactions\n",
    "- DB2: 548 drugs and 48,584 annotated drug-drug interactions. \n",
    "- DB3: 1934 drugs and 230,887 annotated drug-drug interactions.\n",
    "\n",
    "Three different datasets were used by the authors in order to assess the robustness of the model. In my attempt to replicate the authors' results, I only tried using the DB1 and DB3 datasets provided by the authors to guarantee reproducibility.\n",
    "The DB1 and DB3 datasets represent matrices of drug-drug interactions where 1 indicates there is an interaction where 0 indicates no interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1562, 1562)\n",
      "Value: 0.0, Count: 2078692\n",
      "Value: 1.0, Count: 361152\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filename = 'data.h5'\n",
    "data = h5py.File(filename,'r')\n",
    "adj = data['Adj_V4'][:]\n",
    "unique, counts = np.unique(adj.flatten(), return_counts=True)\n",
    "counts = dict(zip(unique, counts))\n",
    "print(f\"Shape: {adj.shape}\")\n",
    "for k, v in counts.items():\n",
    " print(f\"Value: {k}, Count: {v}\")\n",
    "plt.title('Distribution of Values in DB1')\n",
    "plt.pie(counts.values(), labels=counts.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1934, 1934)\n",
      "Value: -1.0, Count: 151980\n",
      "Value: 0.0, Count: 3278582\n",
      "Value: 1.0, Count: 309794\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adj = data['Adj_V5'][:]\n",
    "unique, counts = np.unique(adj.flatten(), return_counts=True)\n",
    "counts = dict(zip(unique, counts))\n",
    "print(f\"Shape: {adj.shape}\")\n",
    "for k, v in counts.items():\n",
    " print(f\"Value: {k}, Count: {v}\")\n",
    "plt.title('Distribution of Values in DB3')\n",
    "plt.pie(counts.values(), labels=counts.keys())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = adj.transpose()\n",
    "adj_copy = copy.deepcopy(adj)\n",
    "adj = sp.csr.csr_matrix(adj)\n",
    "\n",
    "adj_orig = adj\n",
    "adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis,:], [0]), shape=adj_orig.shape)\n",
    "adj_orig.eliminate_zeros()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3muyDPFPbozY"
   },
   "source": [
    "#   Model\n",
    "\n",
    "The following is a diagram representing the DPDDI model. The main steps are as follows: \n",
    "1. The feature extractor of DPDDI constructs a two-layer graph convolutional network (GCN) to obtain drug latent features, which capture the complex relations between the drug nodes in the DDI network.\n",
    "2. Each pair of drugs is represented as a feature vector by concatenating the corresponding latent features of the drugs. \n",
    "3. The feature vectors of representing the drug pairs are fed into a deep neural network to train the predictor to deduce potential DDIs.\n",
    "\n",
    "![dpddi](https://media.springernature.com/full/springer-static/image/art%3A10.1186%2Fs12859-020-03724-x/MediaObjects/12859_2020_3724_Fig2_HTML.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "The following hyperparameters were used to reproduce this model:\n",
    "- **Learning rate**: {0.1, 0.01, 0.001, 0.005, 0.0001}\n",
    "- **Epochs**: {200, 500, 800, 1000, 1200, 1400, 1600}\n",
    "- **Number of units in hidden layers 1 & 2**: {[800,512], [800,256], [800,128], [512,256], [512,128], [512,64], [256,64], [128,32]}\n",
    "- **Weight for L2 loss on embedding matrix**: 0\n",
    "- **Dropout rate (1 - keep probability)**: {0.01, 0.001, 0.0001, 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Auto Encoder (GAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAE Initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBdVZoTvsSFV"
   },
   "outputs": [],
   "source": [
    "def weight_variable_glorot1(input_dim, output_dim, name=\"\"):\n",
    "    \"\"\"Create a weight variable with Glorot & Bengio (AISTATS 2010) initialization.\n",
    "    \"\"\"\n",
    "#    tf.set_random_seed(123)\n",
    "    init_range = np.sqrt(6.0 / (input_dim + output_dim))\n",
    "    initial = tf.random_uniform([input_dim, output_dim], minval=-init_range,\n",
    "                                maxval=init_range, dtype=tf.float32,seed = 12)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "\n",
    "def weight_variable_glorot2(input_dim, output_dim, name=\"\"):\n",
    "    \"\"\"Create a weight variable with Glorot & Bengio (AISTATS 2010) initialization.\n",
    "    \"\"\"\n",
    "#    tf.set_random_seed(231)\n",
    "    init_range = np.sqrt(6.0 / (input_dim + output_dim))\n",
    "    initial = tf.random_uniform([input_dim, output_dim], minval=-init_range,\n",
    "                                maxval=init_range, dtype=tf.float32,seed = 50)\n",
    "    return tf.Variable(initial, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAE Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_LAYER_UIDS = {}\n",
    "\n",
    "def get_layer_uid(layer_name=''):\n",
    "    \"\"\"Helper function, assigns unique layer IDs\n",
    "    \"\"\"\n",
    "    if layer_name not in _LAYER_UIDS:\n",
    "        _LAYER_UIDS[layer_name] = 1\n",
    "        return 1\n",
    "    else:\n",
    "        _LAYER_UIDS[layer_name] += 1\n",
    "        return _LAYER_UIDS[layer_name]\n",
    "\n",
    "\n",
    "def dropout_sparse(x, keep_prob, num_nonzero_elems):\n",
    "    \"\"\"Dropout for sparse tensors. Currently fails for very large sparse tensors (>1M elements)\n",
    "    \"\"\"\n",
    "    noise_shape = [num_nonzero_elems]\n",
    "    random_tensor = keep_prob\n",
    "    random_tensor += tf.random_uniform(noise_shape)\n",
    "    dropout_mask = tf.cast(tf.floor(random_tensor), dtype=tf.bool)\n",
    "    pre_out = tf.sparse_retain(x, dropout_mask)\n",
    "    return pre_out * (1./keep_prob)\n",
    "\n",
    "\n",
    "class Layer(object):\n",
    "    \"\"\"Base layer class. Defines basic API for all layer objects.\n",
    "\n",
    "    # Properties\n",
    "        name: String, defines the variable scope of the layer.\n",
    "\n",
    "    # Methods\n",
    "        _call(inputs): Defines computation graph of layer\n",
    "            (i.e. takes input, returns output)\n",
    "        __call__(inputs): Wrapper for _call()\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        allowed_kwargs = {'name', 'logging'}\n",
    "        for kwarg in kwargs.keys():\n",
    "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
    "        name = kwargs.get('name')\n",
    "        if not name:\n",
    "            layer = self.__class__.__name__.lower()\n",
    "            name = layer + '_' + str(get_layer_uid(layer))\n",
    "        self.name = name\n",
    "        self.vars = {}\n",
    "        logging = kwargs.get('logging', False)\n",
    "        self.logging = logging\n",
    "        self.issparse = False\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        return inputs\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        with tf.name_scope(self.name):\n",
    "            outputs = self._call(inputs)\n",
    "            return outputs\n",
    "\n",
    "\n",
    "class GraphConvolution(Layer):\n",
    "    \"\"\"Basic graph convolution layer for undirected graph without edge labels.\"\"\"\n",
    "    def __init__(self, input_dim, output_dim, adj, dropout=0., act=tf.nn.relu, **kwargs):\n",
    "        super(GraphConvolution, self).__init__(**kwargs)\n",
    "        with tf.variable_scope(self.name + '_vars'):\n",
    "            self.vars['weights'] = weight_variable_glorot1(input_dim, output_dim, name=\"weights\")\n",
    "        self.dropout = dropout\n",
    "        self.adj = adj\n",
    "        self.act = act\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        x = inputs\n",
    "        x = tf.nn.dropout(x, 1-self.dropout)\n",
    "        x = tf.matmul(x, self.vars['weights'])\n",
    "        x = tf.sparse_tensor_dense_matmul(self.adj, x)\n",
    "        outputs = self.act(x)\n",
    "        self.w2 = self.vars['weights']\n",
    "        return outputs,self.w2\n",
    "\n",
    "class DeepConvolution(Layer):\n",
    "    \"\"\"Basic deep  layer for undirected graph without edge labels.\"\"\"\n",
    "    def __init__(self, input_dim, output_dim, dropout=0., act=tf.nn.relu, **kwargs):\n",
    "        super(DeepConvolution, self).__init__(**kwargs)\n",
    "        with tf.variable_scope(self.name + '_vars'):\n",
    "            self.vars['weights'] = weight_variable_glorot2(input_dim, output_dim, name=\"weights2\")\n",
    "        self.dropout = 0.0001\n",
    "        self.act = act\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        x = inputs\n",
    "        x = tf.nn.dropout(x, 1-self.dropout)\n",
    "        x = tf.matmul(x, self.vars['weights'])\n",
    "        outputs = self.act(x)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class GraphConvolutionSparse(Layer):\n",
    "    \"\"\"Graph convolution layer for sparse inputs.\"\"\"\n",
    "    def __init__(self, input_dim, output_dim, adj, features_nonzero, dropout=0., act=tf.nn.relu, **kwargs):\n",
    "        super(GraphConvolutionSparse, self).__init__(**kwargs)\n",
    "        with tf.variable_scope(self.name + '_vars'):\n",
    "            self.vars['weights'] = weight_variable_glorot2(input_dim, output_dim, name=\"weights\")\n",
    "        self.dropout = dropout\n",
    "        self.adj = adj\n",
    "        self.act = act\n",
    "        self.issparse = True\n",
    "        self.features_nonzero = features_nonzero\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        x = inputs\n",
    "        x = dropout_sparse(x, 1-self.dropout, self.features_nonzero)\n",
    "        x = tf.sparse_tensor_dense_matmul(x, self.vars['weights'])\n",
    "        x = tf.sparse_tensor_dense_matmul(self.adj, x)\n",
    "        outputs = self.act(x)\n",
    "        w1 = self.vars['weights']\n",
    "        return outputs,w1\n",
    "\n",
    "\n",
    "class InnerProductDecoder(Layer):\n",
    "    \"\"\"Decoder model layer for link prediction.\"\"\"\n",
    "    def __init__(self, input_dim, dropout=0., act=tf.nn.sigmoid, **kwargs):\n",
    "        super(InnerProductDecoder, self).__init__(**kwargs)\n",
    "        self.dropout = dropout\n",
    "        self.act = act\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        inputs = tf.nn.dropout(inputs, 1-self.dropout)\n",
    "        x = tf.transpose(inputs)\n",
    "        x = tf.matmul(inputs, x)\n",
    "        x = tf.reshape(x, [-1])\n",
    "        outputs = self.act(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, **kwargs):\n",
    "        allowed_kwargs = {'name', 'logging'}\n",
    "        for kwarg in kwargs.keys():\n",
    "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
    "\n",
    "        for kwarg in kwargs.keys():\n",
    "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
    "        name = kwargs.get('name')\n",
    "        if not name:\n",
    "            name = self.__class__.__name__.lower()\n",
    "        self.name = name\n",
    "\n",
    "        logging = kwargs.get('logging', False)\n",
    "        self.logging = logging\n",
    "\n",
    "        self.vars = {}\n",
    "\n",
    "    def _build(self):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def build(self):\n",
    "        \"\"\" Wrapper for _build() \"\"\"\n",
    "        with tf.variable_scope(self.name):\n",
    "            self._build()\n",
    "        variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.name)\n",
    "        self.vars = {var.name: var for var in variables}\n",
    "\n",
    "    def fit(self):\n",
    "        pass\n",
    "\n",
    "    def predict(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class GCNModelAE(Model):\n",
    "    def __init__(self, placeholders, num_features, features_nonzero, **kwargs):\n",
    "        super(GCNModelAE, self).__init__(**kwargs)\n",
    "\n",
    "        self.inputs = placeholders['features']\n",
    "        self.input_dim = num_features\n",
    "        self.features_nonzero = features_nonzero\n",
    "        self.adj = placeholders['adj']\n",
    "        self.dropout = placeholders['dropout']\n",
    "        self.build()\n",
    "\n",
    "    def _build(self):\n",
    "        self.hidden1,self.w1 = GraphConvolutionSparse(input_dim=self.input_dim,\n",
    "                                              output_dim=FLAGS.hidden1,\n",
    "                                              adj=self.adj,\n",
    "                                              features_nonzero=self.features_nonzero,\n",
    "                                              act=tf.nn.relu,\n",
    "                                              dropout=self.dropout,\n",
    "                                              logging=self.logging)(self.inputs)\n",
    "\n",
    "        self.embeddings,self.w2 = GraphConvolution(input_dim=FLAGS.hidden1,\n",
    "                                           output_dim=FLAGS.hidden2,\n",
    "                                           adj=self.adj,\n",
    "                                           act=lambda x: x,\n",
    "                                           dropout=self.dropout,\n",
    "                                           logging=self.logging)(self.hidden1)\n",
    "        self.z_mean = self.embeddings\n",
    "        self.reconstructions = InnerProductDecoder(input_dim=FLAGS.hidden2,\n",
    "                                      act=lambda x: x,\n",
    "                                      logging=self.logging)(self.embeddings)\n",
    "\n",
    "\n",
    "class GCNModelVAE(Model):\n",
    "    def __init__(self, placeholders, num_features, num_nodes, features_nonzero, **kwargs):\n",
    "        super(GCNModelVAE, self).__init__(**kwargs)\n",
    "\n",
    "        self.inputs = placeholders['features']\n",
    "        self.input_dim = num_features\n",
    "        self.features_nonzero = features_nonzero\n",
    "        self.n_samples = num_nodes\n",
    "        self.adj = placeholders['adj']\n",
    "        self.dropout = placeholders['dropout']\n",
    "        self.build()\n",
    "\n",
    "    def _build(self):\n",
    "        self.hidden1 = GraphConvolutionSparse(input_dim=self.input_dim,\n",
    "                                              output_dim=FLAGS.hidden1,\n",
    "                                              adj=self.adj,\n",
    "                                              features_nonzero=self.features_nonzero,\n",
    "                                              act=tf.nn.relu,\n",
    "                                              dropout=self.dropout,\n",
    "                                              logging=self.logging)(self.inputs)\n",
    "\n",
    "        self.z_mean = GraphConvolution(input_dim=FLAGS.hidden1,\n",
    "                                       output_dim=FLAGS.hidden2,\n",
    "                                       adj=self.adj,\n",
    "                                       act=lambda x: x,\n",
    "                                       dropout=self.dropout,\n",
    "                                       logging=self.logging)(self.hidden1)\n",
    "\n",
    "        self.z_log_std = GraphConvolution(input_dim=FLAGS.hidden1,\n",
    "                                          output_dim=FLAGS.hidden2,\n",
    "                                          adj=self.adj,\n",
    "                                          act=lambda x: x,\n",
    "                                          dropout=self.dropout,\n",
    "                                          logging=self.logging)(self.hidden1)\n",
    "\n",
    "        self.z = self.z_mean + tf.random_normal([self.n_samples, FLAGS.hidden2]) * tf.exp(self.z_log_std)\n",
    "\n",
    "        self.reconstructions = InnerProductDecoder(input_dim=FLAGS.hidden2,\n",
    "                                      act=lambda x: x,\n",
    "                                      logging=self.logging)(self.z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAE Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizerAE(object):\n",
    "    def __init__(self, preds, labels, pos_weight, norm):#,w1,w2\n",
    "        preds_sub = preds\n",
    "        labels_sub = labels\n",
    "\n",
    "        self.cost = norm * tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=preds_sub,\\\n",
    "                          targets=labels_sub, pos_weight=pos_weight))   #  +reg_term\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)  # Adam Optimizer\n",
    "\n",
    "        self.opt_op = self.optimizer.minimize(self.cost)\n",
    "        self.grads_vars = self.optimizer.compute_gradients(self.cost)\n",
    "\n",
    "        self.correct_prediction = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(preds_sub), 0.5), tf.int32),\n",
    "                                           tf.cast(labels_sub, tf.int32))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "class OptimizerVAE(object):\n",
    "    def __init__(self, preds, labels, model, num_nodes, pos_weight, norm):  #,w1,w2\n",
    "        preds_sub = preds\n",
    "        labels_sub = labels\n",
    "\n",
    "        self.cost = norm * tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=preds_sub, targets=labels_sub, pos_weight=pos_weight))\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)  # Adam Optimizer\n",
    "\n",
    "        # Latent loss\n",
    "        self.log_lik = self.cost\n",
    "        self.kl = (0.5 / num_nodes) * tf.reduce_mean(tf.reduce_sum(1 + 2 * model.z_log_std - tf.square(model.z_mean) -\n",
    "                                                                   tf.square(tf.exp(model.z_log_std)), 1))\n",
    "        self.cost -= self.kl\n",
    "\n",
    "        self.opt_op = self.optimizer.minimize(self.cost)\n",
    "        self.grads_vars = self.optimizer.compute_gradients(self.cost)\n",
    "\n",
    "        self.correct_prediction = tf.equal(tf.cast(tf.greater_equal(tf.sigmoid(preds_sub), 0.5), tf.int32),\n",
    "                                           tf.cast(labels_sub, tf.int32))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPDDI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPDDI Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_score1(edges_pos, edges_neg,emb=None):\n",
    "    if emb is None:\n",
    "        feed_dict.update({placeholders['dropout']: 0})\n",
    "        emb = sess.run(model.z_mean, feed_dict=feed_dict)\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # Predict on test set of edges\n",
    "    adj_rec = np.dot(emb, emb.T)\n",
    "    preds = []\n",
    "    pred_probability_pos = []\n",
    "    pos = []\n",
    "    for e in edges_pos:\n",
    "        pred_probability_pos.append(adj_rec[e[0], e[1]])\n",
    "        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
    "        pos.append(adj_orig[e[0], e[1]])\n",
    "\n",
    "    preds_neg = []\n",
    "    pred_probability_neg = []\n",
    "    neg = []\n",
    "    for e in edges_neg:\n",
    "        pred_probability_neg.append(adj_rec[e[0], e[1]])\n",
    "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
    "        neg.append(adj_orig[e[0], e[1]])\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    preds_probability_all = np.hstack([pred_probability_pos, pred_probability_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
    "    roc_score = roc_auc_score(labels_all, preds_probability_all)   ## preds_all\n",
    "    precision, recall, pr_thresholds = precision_recall_curve(labels_all, preds_probability_all)\n",
    "    aupr_score = auc(recall, precision)   \n",
    "\n",
    "    return roc_score, aupr_score\n",
    "\n",
    "def get_roc_score2(pre,preds_probability_all,y_test):\n",
    "   \n",
    "    preds_all = np.array(pre)\n",
    "    preds_probability_all = np.array(pre)\n",
    "    labels_all = np.array(y_test)\n",
    "    roc_score = roc_auc_score(labels_all,preds_probability_all)   \n",
    "    \n",
    "    precision, recall, pr_thresholds = precision_recall_curve(labels_all, preds_probability_all )  ##preds_all   preds_probability_all\n",
    "    aupr_score = auc(recall, precision)\n",
    "#    \n",
    "    all_F_measure=np.zeros(len(pr_thresholds))\n",
    "    for k in range(0,len(pr_thresholds)):\n",
    "        if (precision[k]+precision[k])>0:\n",
    "            all_F_measure[k]=2*precision[k]*recall[k]/(precision[k]+recall[k])\n",
    "        else:\n",
    "            all_F_measure[k]=0\n",
    "    max_index=all_F_measure.argmax()\n",
    "    threshold=pr_thresholds[max_index]\n",
    "#        \n",
    "    fpr, tpr, auc_thresholds = roc_curve(labels_all, preds_probability_all)\n",
    "    auc_score = auc(fpr, tpr)\n",
    "    predicted_score=np.zeros(shape=(len(labels_all),1))\n",
    "    predicted_score[preds_probability_all>threshold]=1\n",
    "    confusion_matri = confusion_matrix(y_true=labels_all, y_pred=predicted_score)\n",
    "    print(\"confusion_matrix:\",confusion_matri)\n",
    "        \n",
    "    f=f1_score(labels_all,predicted_score)\n",
    "    accuracy=accuracy_score(labels_all,predicted_score)\n",
    "    precision=precision_score(labels_all,predicted_score)\n",
    "    recall=recall_score(labels_all,predicted_score)\n",
    "\n",
    "    return roc_score, aupr_score,precision, recall,accuracy,f\n",
    "\n",
    "def sparse_to_tuple(sparse_mx):\n",
    "    if not sp.isspmatrix_coo(sparse_mx):\n",
    "        sparse_mx = sparse_mx.tocoo()\n",
    "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "    values = sparse_mx.data\n",
    "    shape = sparse_mx.shape\n",
    "    return coords, values, shape\n",
    "\n",
    "\n",
    "def preprocess_graph(adj):\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    adj_ = adj + sp.eye(adj.shape[0])\n",
    "    rowsum = np.array(adj_.sum(1))\n",
    "    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n",
    "    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n",
    "    return sparse_to_tuple(adj_normalized)\n",
    "\n",
    "\n",
    "def construct_feed_dict(adj_normalized, adj, features, placeholders):\n",
    "    # construct feed dictionary\n",
    "    feed_dict = dict()\n",
    "    feed_dict.update({placeholders['features']: features})\n",
    "    feed_dict.update({placeholders['adj']: adj_normalized})\n",
    "    feed_dict.update({placeholders['adj_orig']: adj})\n",
    "    return feed_dict\n",
    "\n",
    "\n",
    "    \n",
    "def mask_test_edges(adj):\n",
    "    # Remove diagonal elements\n",
    "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
    "    adj.eliminate_zeros()\n",
    "    # Check that diag is zero:\n",
    "    assert np.diag(adj.todense()).sum() == 0\n",
    "\n",
    "    train_edges, train_edges_false, val_edges, val_edges_false, test_edges, test_edges_false = [],[],[],[],[],[]\n",
    "    adj_train = []\n",
    "\n",
    "    link_number = 0\n",
    "    non_link_number = 0\n",
    "    link_position = []\n",
    "    non_link_position = []  # all non-link position\n",
    "    for i in range(0, adj.shape[0]):\n",
    "        for j in range(i + 1, adj.shape[1]):\n",
    "            if adj[i, j] == 1:\n",
    "                link_number = link_number + 1\n",
    "                link_position.append([i, j])\n",
    "            elif adj[i,j] ==0:\n",
    "                non_link_number = non_link_number +1\n",
    "                non_link_position.append([i,j])\n",
    "\n",
    "\n",
    "    link_position = np.array(link_position)\n",
    "    non_link_position = np.array(non_link_position)\n",
    "    seed = 12\n",
    "    random.seed(seed)\n",
    "    link_index = np.arange(0, link_number)\n",
    "    non_link_index = np.arange(0, non_link_number)\n",
    "    random.shuffle(link_index)\n",
    "    random.shuffle(non_link_index)\n",
    "    kfold = 5\n",
    "    num_train_kd = link_number// kfold\n",
    "    num_test_kd = int(np.floor(num_train_kd * 0.2))\n",
    "    num_val_kd = int(np.floor(num_train_kd * 0.5))   #num_train_kd / 20.\n",
    "    num_negtive_kd = non_link_number // kfold\n",
    "    \n",
    "    for i in range(kfold):\n",
    "        train_link_index = link_index[i *num_train_kd:(i+1)*num_train_kd]        \n",
    "        test_link_index = train_link_index[0:num_test_kd]\n",
    "        val_link_index = train_link_index[num_test_kd:num_test_kd + num_val_kd]\n",
    "        train_index = train_link_index[num_test_kd + num_val_kd:num_train_kd]\n",
    "        \n",
    "        train_index.sort()\n",
    "        val_link_index.sort()\n",
    "        test_link_index.sort()       \n",
    "        train_edges.append(link_position[train_index])\n",
    "        val_edges.append(link_position[val_link_index])\n",
    "        test_edges.append(link_position[test_link_index])\n",
    "        \n",
    "        fold =6\n",
    "        kd_no_link_index = non_link_index[i*num_negtive_kd:(i+1)*num_negtive_kd]\n",
    "        test_no_link_index = kd_no_link_index[0: fold * num_test_kd]\n",
    "        val_no_link_index = kd_no_link_index[fold * num_test_kd:fold * (num_test_kd + num_val_kd)]\n",
    "        train_no_link_index = kd_no_link_index[fold * (num_test_kd + num_val_kd):num_negtive_kd]\n",
    "        train_no_index = train_no_link_index\n",
    "        \n",
    "        train_no_index.sort()\n",
    "        val_no_link_index.sort()\n",
    "        test_no_link_index.sort()       \n",
    "        train_edges_false.append(non_link_position[train_no_index])\n",
    "        val_edges_false.append(non_link_position[val_no_link_index])\n",
    "        test_edges_false.append(non_link_position[test_no_link_index])\n",
    "        data = np.ones(np.array(train_edges).shape[1])\n",
    "        # Re-build adj matrix\n",
    "        adj_train_rebuild = sp.csr_matrix((data, (np.array(train_edges)[0, :, 0], np.array(train_edges)[0, :, 1])), shape=adj.shape)\n",
    "        adj_train_rebuild = adj_train_rebuild + adj_train_rebuild.T\n",
    "        adj_train.append(adj_train_rebuild)\n",
    "    \n",
    "    return adj_train, train_edges, train_edges_false,val_edges, val_edges_false, test_edges, test_edges_false\n",
    "\n",
    "def node_trans_edges(test_edges,test_edges_false,val_edges,val_edges_false,train_edges,train_edges_false):\n",
    "    if type(test_edges) != list:\n",
    "        test_edges = test_edges.tolist()\n",
    "    if type(train_edges_false) != list:\n",
    "        train_edges_false = train_edges_false.tolist()\n",
    "    if type(train_edges) != list:\n",
    "        train_edges = train_edges.tolist()\n",
    "    if type(test_edges_false) != list:\n",
    "        test_edges_false = test_edges_false.tolist()  \n",
    "    if type(val_edges) != list:\n",
    "        val_edges = val_edges.tolist() \n",
    "    if type(val_edges_false) != list:\n",
    "        val_edges_false = val_edges_false.tolist() \n",
    "        \n",
    "    x_train_index = train_edges + train_edges_false\n",
    "    y_train = [1]*len(train_edges) + [0] * len(train_edges_false)\n",
    "    x_val_index = val_edges + val_edges_false\n",
    "    y_val = [1]*len(val_edges) + [0] * len(val_edges_false)\n",
    "    x_test_index = test_edges + test_edges_false\n",
    "    y_test = [1]*len(test_edges) + [0] * len(test_edges_false)\n",
    "    x_train = []\n",
    "    x_val = []\n",
    "    x_test = []\n",
    "    \n",
    "    ###transform node embdding to edges feature by concat opration \n",
    "    t = time.time()\n",
    "    for i in range(len(x_train_index)):\n",
    "        x_train.append(np.hstack((embedding[ x_train_index[i][0]],embedding[ x_train_index[i][1]])))\n",
    "    for i in range(len(x_val_index)):\n",
    "        x_val.append(np.hstack((embedding[ x_val_index[i][0]],embedding[ x_val_index[i][1]])))\n",
    "    for i in range(len(x_test_index)):\n",
    "        x_test.append(np.hstack((embedding[ x_test_index[i][0]] ,embedding[ x_test_index[i][1]])))\n",
    "    print(\"cost time of embedding concat\", time.time()-t)\n",
    "    \n",
    "    y_train = utils.to_categorical(y_train, 2)\n",
    "    y_test = utils.to_categorical(y_test, 2)\n",
    "    y_val =  utils.to_categorical(y_val, 2)\n",
    "    \n",
    "    x_train = np.matrix(x_train)\n",
    "    x_test = np.matrix(x_test)\n",
    "    x_val = np.matrix(x_val)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "    y_val = np.array(y_val)\n",
    "    print(\"fill embedding data accomplishment\")\n",
    "    return x_train, x_test, x_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPDDI Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "        self.interval = interval\n",
    "        self.x_val,self.y_val = validation_data\n",
    "    def on_epoch_end(self, epoch, log={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.x_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print('\\n ROC_AUC - epoch:%d - score:%.6f \\n' % (epoch+1, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DPDDI Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "flags = tf.compat.v1.flags\n",
    "FLAGS = flags.FLAGS\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "try:\n",
    "    flags.DEFINE_string('f','','')\n",
    "except tf.compat.v1.flags.DuplicateFlagError:\n",
    "    pass\n",
    "try:\n",
    "    flags.DEFINE_float('learning_rate', 0.001, 'Initial learning rate.')\n",
    "except tf.compat.v1.flags.DuplicateFlagError:\n",
    "    pass\n",
    "try:\n",
    "    flags.DEFINE_integer('epochs', 1200, 'Number of epochs to train.')\n",
    "except tf.compat.v1.flags.DuplicateFlagError:\n",
    "    pass\n",
    "try:\n",
    "    flags.DEFINE_integer('hidden1', 700, 'Number of units in hidden layer 1.')\n",
    "except tf.compat.v1.flags.DuplicateFlagError:\n",
    "    pass\n",
    "try:\n",
    "    flags.DEFINE_integer('hidden2', 256, 'Number of units in hidden layer 2. ')\n",
    "except tf.compat.v1.flags.DuplicateFlagError:\n",
    "    pass\n",
    "try:\n",
    "    flags.DEFINE_float('weight_decay', 0, 'Weight for L2 loss on embedding matrix.')\n",
    "except tf.compat.v1.flags.DuplicateFlagError:\n",
    "    pass\n",
    "try:\n",
    "    flags.DEFINE_float('dropout', 0., 'Dropout rate (1 - keep probability).')\n",
    "except tf.compat.v1.flags.DuplicateFlagError:\n",
    "    pass\n",
    "try:\n",
    "    flags.DEFINE_string('model', 'gcn_ae', 'Model string.')\n",
    "except tf.compat.v1.flags.DuplicateFlagError:\n",
    "    pass\n",
    "try:\n",
    "    flags.DEFINE_string('dataset', 'cora', 'Dataset string.')\n",
    "except tf.compat.v1.flags.DuplicateFlagError:\n",
    "    pass\n",
    "try:\n",
    "    flags.DEFINE_integer('features',0, 'Whether to use features (1) or not (0).')\n",
    "except tf.compat.v1.flags.DuplicateFlagError:\n",
    "    pass\n",
    "\n",
    "model_str = 'gcn_ae'\n",
    "\n",
    "data = h5py.File(filename,'r')\n",
    "adj = data['Adj_V5'][:]\n",
    "adj = adj.transpose()\n",
    "adj_copy = copy.deepcopy(adj)\n",
    "adj = sp.csr.csr_matrix(adj)\n",
    "\n",
    "# Store original adjacency matrix (without diagonal entries) for later\n",
    "adj_orig = adj\n",
    "adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis,:], [0]), shape=adj_orig.shape)\n",
    "adj_orig.eliminate_zeros()\n",
    "\n",
    "if FLAGS.features == 0:\n",
    "    features = sp.identity(adj.shape[0])  # featureless\n",
    "\n",
    "# Define placeholders\n",
    "placeholders = {\n",
    "    'features': tf.sparse_placeholder(tf.float32),\n",
    "    'adj': tf.sparse_placeholder(tf.float32),\n",
    "    'adj_orig': tf.sparse_placeholder(tf.float32),\n",
    "    'dropout': tf.placeholder_with_default(0., shape=())\n",
    "}\n",
    "\n",
    "num_nodes = adj.shape[0]\n",
    "\n",
    "features = sparse_to_tuple(features.tocoo())\n",
    "num_features = features[2][1]\n",
    "features_nonzero = features[1].shape[0]\n",
    "\n",
    "adj_train, train_edges, train_edges_false, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
    "roc_score_arr,aupr_score_arr,precision_arr, recall_arr,accuracy_arr,f_arr = [],[],[],[],[],[]\n",
    "print(\"split end\")\n",
    "CV = 5\n",
    "for i in range(CV):\n",
    "    adj = adj_train[i]\n",
    "    adj_norm = preprocess_graph(adj)\n",
    "    model = GCNModelAE(placeholders, num_features, features_nonzero)\n",
    "\n",
    "    pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "    norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "    with tf.name_scope('optimizer'):      # Optimizer\n",
    "        if model_str == 'gcn_ae':\n",
    "            opt = OptimizerAE(preds=model.reconstructions,\n",
    "                          labels=tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\n",
    "                                                                      validate_indices=False), [-1]),\n",
    "                          pos_weight=pos_weight,\n",
    "                          norm=norm)\n",
    "        \n",
    "    sess = tf.Session()    # Initialize session\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    cost_val = []\n",
    "    acc_val = []\n",
    "    val_roc_score = []\n",
    "    \n",
    "    adj_label = [a + sp.eye(adj_train[0].shape[0]) for a in adj_train]\n",
    "    print(type(adj_label[0]))\n",
    "    print(adj_label[0].shape)\n",
    "    adj_label = [sparse_to_tuple(a) for a in adj_label]\n",
    "    for epoch in range(FLAGS.epochs):# Train model   #train_loss, train_acc= [],[]\n",
    "        t = time.time()\n",
    "        feed_dict = construct_feed_dict(adj_norm, adj_label, features, placeholders)    # Construct feed dictionary\n",
    "        # feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "        # Run single weight update\n",
    "        outs = sess.run([opt.opt_op, opt.cost, opt.accuracy], feed_dict=feed_dict)\n",
    "        # Compute average loss\n",
    "        avg_cost = outs[1]\n",
    "        avg_accuracy = outs[2]\n",
    "        train_loss.append(avg_cost)\n",
    "        train_acc.append(avg_accuracy)\n",
    "        roc_curr, aupr_score = get_roc_score1(val_edges, val_edges_false)\n",
    "        print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(avg_cost),\n",
    "          \"train_acc=\", \"{:.5f}\".format(avg_accuracy), \"val_roc=\", \"{:.5f}\".format(val_roc_score[-1]),\n",
    "          \"val_ap=\", \"{:.5f}\".format(aupr_score),\n",
    "          \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "    print(\"Optimization Finished!\")\n",
    "    x_train, x_test, x_val, y_train, y_test, y_val = node_trans_edges(test_edges[i],test_edges_false[i],val_edges[i],val_edges_false[i],train_edges[i],train_edges_false[i])\n",
    "    RocAuc = RocAucEvaluation(validation_data=(x_val,y_val), interval=1)\n",
    "\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, activation='relu', input_shape=(256,)))\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(128,)))\n",
    "    model.add(layers.Dense(32, activation='relu', input_shape=(64,)))\n",
    "    model.add(layers.Dense(2, activation='softmax'))\n",
    "    model.compile(optimizer=optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0),   ##  optimizer='adam'\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy])\n",
    "    print(\"model compile finished, model fit begin\")\n",
    "    model.fit(x_train,y_train, batch_size=50, epochs=200,validation_data=(x_val, y_val), callbacks=[RocAuc], verbose=2)\n",
    "    pre = model.predict(x_test)\n",
    "    pre_lab = np.argmax(model.predict(x_test), axis=1)\n",
    "    y_test = [y_test[i][1] for i in range(len(y_test))]\n",
    "    pre_probability = [pre[i][1] for i in range(len(pre))]\n",
    "    \n",
    "    roc_score,aupr_score,precision, recall,accuracy,f = get_roc_score2(pre_lab,pre_probability,y_test)\n",
    "    roc_score_arr.append(roc_score)\n",
    "    aupr_score_arr.append(aupr_score)\n",
    "    precision_arr.append(precision)\n",
    "    recall_arr.append(recall)\n",
    "    accuacy_arr.append(accuracy)\n",
    "    f_arr.append(f)\n",
    "    print(roc_score,aupr_score,precision, recall,accuracy,f)\n",
    "\n",
    "roc_score = np.mean(roc_score_arr)\n",
    "aupr_score = np.mean(aupr_score_arr)\n",
    "precision = np.mean(precision_arr)\n",
    "recall = np.mean(recall_arr)\n",
    "accuracy = np.mean(accuacy_arr)\n",
    "f = np.mean(f_arr)\n",
    "\n",
    "print( \"roc_score=\", \"{:.5f}\".format(roc_score), \"aupr_score =\", \"{:.5f}\".format(aupr_score ),\n",
    "          \"precision=\", \"{:.5f}\".format(precision),  \"recall=\", \"{:.5f}\".format(recall),\n",
    "            \"accuracy =\", \"{:.5f}\".format(accuracy ),  \"f =\", \"{:.5f}\".format(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics Descriptions\n",
    "- **ROC Score**: The ROC score can be any values between 0 and 1 inclusive. A larger number represents better performance, where 1 indicates a perfect model. A random model would have a score of 0.5.\n",
    "- **Precision**: Calculated as the number of true positives divided by the total number of true positives and false positives predicted.\n",
    "- **Accuracy**: Calculated as the number of correct predictions divided by the total number of samples.\n",
    "- **AUPR Score**: The AUPR score represents the relationship between precision and recall and has a different baseline depending on the data.\n",
    "- **Recall**: Calculated as the number of true positives divided by the total number of true positives and false negative predicted.\n",
    "- **f**: 2 x (Precision*Recall)/(Precision + Recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gX6bCcZNuxmz"
   },
   "source": [
    "# Results\n",
    "I was not able to reproduce the original results based on the model provided. If given more time one could recreate the model from scratch or using more contemporary packages using the high-level description in the original paper.\n",
    "\n",
    "### Experiments beyond the original paper\n",
    "My experiment beyond the original paper was my attempt to refactor the model to be compatible with newer versions of dependencies such as Python, SciPy, NumPy, and Tensorflow. I believe this would be extremely useful so that researchers or developers could use this model without the need to meticulously recreate the environment used in 2020. Using the original environment would also be problematic when trying to integrate the model implementation with contemporary scripts and tools that are most likely incompatible with the code provided. I was not successful with this experiment, as is explained in more detail under Discussion>What was difficult.\n",
    "\n",
    "### Ablation Study\n",
    "I was not able to successfully complete an ablation study because of the time spent refactoring the model and fixing the broken code. In the future it would be insightful to perform the following studies:\n",
    "\n",
    "- Compare various feature operators for aggregating drug feature vectors into DDI feature vectors. Three operators were tested by Feng et al. These are inner product, summation and concatenation. I could recreate this study and compare my results to those of the authors. The creation of DDI features using GCN and aggregation is a novel methodology and there are many possible approaches to the aggregation step in particular. For these reasons, it is important to understand the impact of aggregation methods on model performance and to recommend a particular method for this use case.\n",
    "\n",
    "- Compare the GCN-derived DDI features with hand-crafted features that represent the chemical, biological, and clinical properties of each drug. By training a DNN with hand-crafted features and then comparing that modelâ€™s performance to the same DNN trained with GCN-derived features, we can observe the hypothesized benefit of using a GCN to build features for this use case. This will highlight the importance of the first step of the two-fold solution described above and prove its superiority over using a DNN alone. Feng et al. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qH75TNU71eRH"
   },
   "source": [
    "# Discussion\n",
    "\n",
    "### Implications of the experimental results\n",
    "Reproducing the original experiment with the provided code was not possible because the required packages were incompatible and my attempt to refactor the code to work with contemporary versions of the same required packages was unsuccessful after many hours of effort. In addition, the authors' code was incomplete and not runnable as provided in the GitHub repo associated with the paper. \n",
    "\n",
    "In future efforts I would attempt to recreate the model from scratch using one of several new graph neural network packages that are available and more thoroughly tested instead of relying on the Graph Auto Encoder implementation cited in this paper. Using a newer, mature package for graph neural networks would improve reproducibility by being done using source code that's tracked by package repositories like conda-forge and pypi. Overall the data provided in the paper is promising and shows potential for being used in a real way to provide recommendations for targeted testing and study of specific drug-drug interactions that might have not been flagged otherwise.\n",
    "\n",
    "### What was easy\n",
    "It was helpful to have such extensive starter code available in a GitHub repository as a starting point for reproducing this model. It was also helpful to have data available for download in the MATLAB file so that I did not need to retrieve the data from DrugBank and generate the interaction matrices myself. \n",
    "\n",
    "Overall, the paper itself was easy to understand and written well at a high level, which made getting started with this project easy. I think the authors did a good job of conceptually explaining the challenge that they attempt to solve, the methodologies they planned to use, and the value of the ablation studies performed.\n",
    "\n",
    "### What was difficult\n",
    "The package versions used in the paper are from 2018 and no longer commonly used and so recreating the exact environment used by the authors was key to being successful, however it was very difficult. The packages of numpy (1.15.4) and tensorflow (1.15.2) used in the study are officially incompatible, as tesorflow 1.15.2 requires numpy 1.16.0 or greater. Scikit-learn was also not listed as a requirement even though it is used extensively in the model code. I guessed through trial and error which version of scikit-learn was used by the authors and therefore compatible with the other dependencies (0.19.2). \n",
    "\n",
    "Originally I planned to update the code from the authors to be compatible with the most recent versions of the required packages. My attempt at this was not successful, as the behaviors of scipy and tensorflow in particular have changed a lot and many breaking changes have been made between the old and new versions.  The paper is from 2020, and the package versions used were released as long ago as 2018. I attempted to refactor the model but after over 20 hours of effort I could not get it to work and could not reproduce the authors' results.\n",
    "\n",
    "In addition, the code provided by the authors seemed to be incomplete or changed from the working state demonstrated in the paper. At least 5 key variables in the Python code were referenced but not defined, and so I had to guess what the intended value was in order to get the model working. In addition, there were very minimal code comments or documentation for the code itself. While the paper clearly describes the model at a high level, the implementation is somewhat convoluted.  \n",
    "\n",
    "Finally, it was not clear how to use the DATA.mat file provided by the authorsand there were no descriptions of the variables within it once I figured out how to open the file. Furthermore, the model code expected a HDF5 file which was not provided.\n",
    "\n",
    "### Recommendations to the original authors or others who work in this area for improving reproducibility\n",
    "I recommend publishing code that is cleaner and follows common reproducibility guidelines, for example: https://koustuvsinha.com//practices_for_reproducibility/. This would be more helpful to those trying to reproduce the model or build upon it. I also recommend adding more documentation and code comments to the model and the data provided with the model code. For example, it would have been very useful to provide instructions on preparing the test data for use with the model implementation provided.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SHMI2chl9omn"
   },
   "source": [
    "# References\n",
    "\n",
    "1.   Feng, YH., Zhang, SW. & Shi, JY. DPDDI: a deep predictor for drug-drug interactions. BMC Bioinformatics 21, 419 (2020). https://doi.org/10.1186/s12859-020-03724-x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
